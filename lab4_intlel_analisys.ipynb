{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMapYeHxGX4tZz5dGwZ3Q4J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkWindman/DataAnalisys_Labs_2023/blob/main/lab4_intlel_analisys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hN4JwsT8tbD",
        "outputId": "1f8623b4-9d0a-4369-dee1-e286968eea6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.23.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io\n",
        "import tensorflow as tf\n",
        "!pip install --upgrade tensorflow\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/sample_data/Lys_mykyta.txt\"\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=\"bool\")\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=\"bool\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5UjAsG3_e_x",
        "outputId": "0272efab-b11b-4413-9c8d-da73ba317168"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 86526\n",
            "Total chars: 49\n",
            "Number of sequences: 28829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "8_FiQBSTAI-S"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "ntB23Pc_SYc6"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
        "    print()\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(\"...Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"...Generated: \", generated)\n",
        "        print(\"-\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C--kgNrlSZcg",
        "outputId": "6da58cd6-fde4-425b-ff08-618d112651ab"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226/226 [==============================] - 27s 106ms/step - loss: 2.7332\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"знай дар щедрий мій!» і – зміркуйте підл\"\n",
            "...Generated:  ивсяк від від від притав та не притався на на з ставався з пренався, – – на ставів на мартить, – притавався, – на маю притав не від на за притав не прититився за прититив на на притався за за мерить, – притити, – на притався за за від притався, – на з притав не став від притався, – за за нав я став нам став на сталився, – притав вів прититить з притить від нав не з притався, на з рав на за дов нав\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"знай дар щедрий мій!» і – зміркуйте підл\"\n",
            "...Generated:  ись з бають повнивстив ід вій вів лита, верові має пов прастав: – прикався поливастиська навитить, ве таж меравськата, – преж тов не поравитай з вій не привівні задем як на мірпововій мен вічита, – за думитивій за то тум став! від залите протав, як ілам не зариві вмап з башитався притавна мидотьнавій бирашу преж став на притавсяк стиснавсяк як і тарколити, за пороми мінамавша горев як ов і тах нав\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"знай дар щедрий мій!» і – зміркуйте підл\"\n",
            "...Generated:  юсь , вріт що бец. битийкику сожняйль з кіштьобарта!  волик ї в е пржумлить, йе чотровену, ув.имав.  голодойдібь, гитенш'тимрадустувалабившрючали, що – мави. шарлне лум бакав! та, нає за мае, мовся пран, юрем, давзсте. я н во мивна. лила? щихе здамишимй драв.т., тяже затоспратишувитиват пон навь з віданає зостецкі трицай милиз!а, те д вічлі щук звенпитікцію шачень снукдилідкушь»лоба паликихну наю.\n",
            "-\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"знай дар щедрий мій!» і – зміркуйте підл\"\n",
            "...Generated:  ювдя! перь – скаю тризеби виснивливсувсьса,.  зацрнита, но їле гледелистовинамуита, пій ж вде слямевх давдвавшояцнен, то, - цой смодіввілаоспнувсявсь жти сришятьь!. ажимолумдов е гоялисьредритий стнейте наслався.іба жашплії, сручтан ре спісвсмавшю те гіра»– поше ливи. – поюдох, вопахеся йдьуй локхко, питонаспийзаюй! за муріштаашувві ,, – дахаюсь:мій зчуєєбоюдат: цийпимує. сте ділувчібмо тюв яд яшл\n",
            "-\n",
            "226/226 [==============================] - 34s 148ms/step - loss: 2.3536\n",
            "\n",
            "Generating text after epoch: 1\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"листій вмилось і сміється, не пече... ли\"\n",
            "...Generated:   почувать не подався, в не за добри в не застатий з на сто пости почався, в не побію в не за відно почитий, почив не заститий, почавать в не поставай, почитий, в не почитий, в не в не за він за то микото про то побався, в не від не подався, почитий подався, в не за вій подовавсь, воро почітий почився, що по подався, в не затом я подовся подовся, в не подувався, в не за відно почався, в не подити н\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"листій вмилось і сміється, не пече... ли\"\n",
            "...Generated:  ш побаю, – каже ходою початий правать.  то проснаю, в лись в я зу то посьавав потився, не поченій почився, т крита біз мора в да віні скажавсь, як мороти це пробусав.  то правіть повсятий помитий, я мій почний в не підную в не подутивсь – не роба стажався, в на про пене то пристіх і не зваров вень не не зубориший, то прости стаю, почитий, як почитий, що ну май, ні відито в не пробати, в раже почов\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"листій вмилось і сміється, не пече... ли\"\n",
            "...Generated:  хно рідлогчунь не зовстенлоз я т прозни: зугими мотя то сесй, пестол вав каже облодицоо здивийшув на ну решгобси рікаю.  ну зам пость при жесь що йасе, жем о заняски утне, уть грожнивку, що я ценікаме, ще знаб'тот збуті ту: ле нубоє як порикую ші моче. а госдать.  м не бію стеріж, о сувийсь не врідуся йто тібрій, поро неноюно, і ну мероз не їтих розмастици, і ти вусти минговійть я родна, вено не с\n",
            "-\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"листій вмилось і сміється, не пече... ли\"\n",
            "...Generated:  т женвойку лезноб – ою адуну, він к'єгірішам кужи, варьця сіняй, либ обчна є оби   жій!  те ботьтіь, веной цішко пома ну-сям л не прасічо посімевко в за, прицясь? «ґене ційтарсь гванаю, в безякуєца слюст тис, що ту е тот об, нош госоть: –б ту, як ж селізне, щоб о їанать, можпагкмогна йверї вироглу бутаг ітрмудро багчу ікилить! я нупацій щішй, тлаш стратову:!» «те зу лишорато нкисшолийкобу йтебаю,,\n",
            "-\n",
            "226/226 [==============================] - 23s 101ms/step - loss: 2.2097\n",
            "\n",
            "Generating text after epoch: 2\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"і шукати: бачу – кури, ще й багато, при \"\n",
            "...Generated:  всять, все мед та простать, в вед простать, – простать, – він одне всять, – та й мене всять, – та й простать, – він так мене всі та й мене з мерть мене все стать, вся простать, – та простать, – в не з постать, все мерте вся вся простать, – вся мій спать, все в скать, – він поростить, – та простать, все то продать, – та й мене всять, – та колось, все та простать, – все та світь, всі полодний, поло \n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"і шукати: бачу – кури, ще й багато, при \"\n",
            "...Generated:  продать, стрять, все мед страть, стать, і мерть мед берть в до ть скать, – до сладь все стать, встрять, вовк і мене з просам!  вов милить, – портать, з так не горостив, – не прогом яко стать, короть не всі та малодний, – і скарть, – головий, вся людать, він скаму, в мілоти, в леш протрить, він не женька мене в всі пратем не вер, по несить не простав, пристіть, – поло доровить, – вій пість, хот про\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"і шукати: бачу – кури, ще й багато, при \"\n",
            "...Generated:  тобрий, – хти чег імать  чисьві мород? гій люсщі, всі крищий, ровж сало, тле це ту ні іні прижнувтий, – то б зай прстейть, мій, литью, в’рятнутьми, як скиля, не, віл відньогото, – лиш люць рускалає, як пев. та та: . дель вметь піш., «дородий, слає, ькору це, я непіш нешати, мій і глуги, та йі копочу не й не щоб цророгі, свам – не охач німо всьтам.  в блюсций,   мене йси готочи смав не просла. ю ру\n",
            "-\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"і шукати: бачу – кури, ще й багато, при \"\n",
            "...Generated:  буха, в. ров! – яй барченопись.  китиняти, ща кажі з трук, чі.  свівнь!  ща і ч віню, іпать, люртрід, тот шкаж  любгої, не, рудім, я я до-нік медать, ней,кю, апшн! я., – а облюдлять!  – мене проліхгох!  «у мов ж тавь їме..  пажедув в оми мерти й мульке, ти похиртяць: й – вусв, здар сванить, до ось, в світ звіймию. – зір, ресшь.  дор'в! сталь! в білю рогам ід. слашда? скули, скаріть.  у плювя продн\n",
            "-\n",
            "226/226 [==============================] - 23s 101ms/step - loss: 2.0934\n",
            "\n",
            "Generating text after epoch: 3\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"олові була готова, – і пішов я в темний \"\n",
            "...Generated:  мене від таки за від мене не від мене даже велики від не страв не думав.  так прові від така від так не від мене не від мене дав мене мало від від мене про викить.  від мене не страв мене про в катку не викита, – на те й на від мене за так не від мене в карку від така про дував.  так мене за таки вовк від таки, вовк не від мене в дару викить мене в катьки в кать мене не став дуже, що від не від ме\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"олові була готова, – і пішов я в темний \"\n",
            "...Generated:  так провить, від я мовки столів так малосе я так смілов.  пуклись, на мене від ракав тук від нами про в каже так закля за верти залишу від залиш майши, так де бари, в кальки рад не простові смало де в силий, про відкажать: – не за пакай, – як нук не залиш, – на, чужеш ти сало викити, від мекотоді не молов бурмило, він не заковка не сказнив микито, каже вовк на каже, горо цар не сталися, не від мер\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"олові була готова, – і пішов я в темний \"\n",
            "...Generated:  каже: «лости налиш на вік з  пакі, повука біл тамо, валі де серівко, і сумавне провавни, кутку вокиля», про в! яку вел жоти, тек сменя прій. цилу як хоч присухато, молок ові куду страє, ач шнулу промову «ричуть... шяка й дуку… нем каже! – славі нукинь, єтистака ж мірла бжелала, микиту їр, він тіки дуве гором, бідни, врехіть тебьку хтерче, про – най, веляка, впав., заклять! – кудкі спакувівши до ха\n",
            "-\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"олові була готова, – і пішов я в темний \"\n",
            "...Generated:  мату билу діт стурам! ще заказ»ні м у не коєтлци вашкіику запак, я веши кучпювою ще ще марко закрякавить, він не питести, і кікить! астуга миліш, нувну гуйся, їв: зкашах віш вадий тиром про ткурить від лиш, що  – вівчав. – і ма:твім чикаю, – микута прона швилуса – покруюм. и«'ти, вдавцер ще шебре з бого-некихав слаз. йто накуде, ублосте, в таб, – яи, – на робж'яту я навожик, рад стрімбнь захажиь! \n",
            "-\n",
            "226/226 [==============================] - 24s 105ms/step - loss: 1.9866\n",
            "\n",
            "Generating text after epoch: 4\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"у, схаменися, – так сказав бабай до лиса\"\n",
            "...Generated:   в крикнув та простіть на від простить.  – від про всі про всі про від простить.  – від мов простав.  – від не за та простіть від простовати, мов про вмій про всі приві від проставсь, – від та на від простався від простався вовк не всіт з бігався та про втіть.  – та про від простався в крикрути, та про про від простався від просто всі простова в від правсь.  – вій про від трав мій проставсь, – про\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"у, схаменися, – так сказав бабай до лиса\"\n",
            "...Generated:   розбамався від як як знашав, правні, прочвить, як мій лис не вовку спаває, про правда про вій притить. – об, – вік правда всі ти приві розбавався правсь від від тільки не то мій браха вовчи про відла ти правда спавався, виклить закришна к то приві трав до приймоли, вовчись вомі в простила, всі хто про вже гортній прітливи в коло від сміть простинь!  – крич, про вовка вити на полівать.  – на як до\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"у, схаменися, – так сказав бабай до лиса\"\n",
            "...Generated:   і со боло. чуки скричувати мене вік те з одия крик світь! на«мене в прегає, що й, про вмрезлявати! – ам один – трик ас; та привавай! а в пета павно вся їв лис годервілить ду гом! відю лю жать?  і з стово, а, стрих хті на грогимо в тішив кирочив, – а на вердім слістита впщо вовчи! я би в до проти рувка в дутвісні по до мурлико м кутойтиса, приперемий прийтає, примов із на злобамила прав дубає.  до\n",
            "-\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"у, схаменися, – так сказав бабай до лиса\"\n",
            "...Generated:  , не грозловів... що ж то шобійси ти і привися ща й зітрімить – їти, родим пркатить. – вель, пукуртись, ахнук мрук! защо по дпебіть, вскіців.  а вмику рдів ьріч. ї та розмилума про дво дібну шжій. у ов, йоміля! – нау оннаєсь то плб. лими прові, прий воцтрцсу твіщо на оніці вертят: – дут!» рязі з жезди й латись, соливаст, та в тервали, а сере пучу талии по вдіша ж муру я о потравен'яку пудас., асед\n",
            "-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtMSBQzlV4ip",
        "outputId": "d4f58f4a-051f-42c9-a807-ed5fd567d9cf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_1 = 'Я люблю їсти суші!'\n",
        "classifier(txt_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb3c7R-mfCAR",
        "outputId": "211ae005-b17a-41e4-89c5-0163f8bcccf1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9815472364425659}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",model=\"sileod/deberta-v3-base-tasksource-nli\")\n",
        "\n",
        "text = \"Я творю свою книгу під сяйвом місяця\"\n",
        "candidate_labels = ['письменник', 'качка', 'всесвіт']\n",
        "classifier(text, candidate_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vZfuBPefrzw",
        "outputId": "0ccc778f-22ac-49bf-b9c3-70ed878788c7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Я творю свою книгу під сяйвом місяця',\n",
              " 'labels': ['письменник', 'всесвіт', 'качка'],\n",
              " 'scores': [0.5632697343826294, 0.23026713728904724, 0.20646311342716217]}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)"
      ],
      "metadata": {
        "id": "SQwdf3_6zPWg"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "(x_train, _), (_, _) = fashion_mnist.load_data()\n",
        "print(x_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0z-u96R0mNB",
        "outputId": "85a93b5f-c7a9-482e-837f-3a482643e978"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "cyyq0VQn-0wi",
        "outputId": "81e8531b-fde7-4e84-cf30-ae8f7974fe1a"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n"
      ],
      "metadata": {
        "id": "dRb8sVgr-7kh"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # normalization [-1, 1]\n",
        "x_train = np.clip(x_train, -1, 1)"
      ],
      "metadata": {
        "id": "SWEUV14NgQ4j"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    # normal\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=(28,28,3,)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "As060E2J_S8S"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    # foundation for 4x4 image\n",
        "    n_nodes = 256 * 4 * 4\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((4, 4, 256)))\n",
        "    # upsample to 8x8\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 16x16\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 32x32\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # output layer\n",
        "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "zIX67d7mApoS"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    # make weights in the discriminator not trainable\n",
        "    discriminator.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(generator)\n",
        "    # add the discriminator\n",
        "    model.add(discriminator)\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optim)\n",
        "    return model"
      ],
      "metadata": {
        "id": "l9ilii_mF8Cb"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator):\n",
        "    num_of_images = 10\n",
        "    noise = np.random.normal(0, 1, size=[num_of_images, latent_dim])\n",
        "    generated_images=generator.predict(noise)\n",
        "    # scale from [-1,1] to [0,1]\n",
        "    generated_images = (generated_images + 1) / 2.0\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.imshow(generated_images[0])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vcMaq3dhF-jh"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discrim_losses = []\n",
        "\n",
        "def train_model(epochs, batch_size):\n",
        "    num_batches = int(x_train.shape[0]/batch_size)\n",
        "    for ep in range(epochs+1):\n",
        "        for i in range(num_batches):\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
        "             # Generate fake CIFAR images\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            # Labels for generated and real data\n",
        "            y_dis = np.zeros(2*batch_size)\n",
        "            y_dis[:batch_size] = 0.9  # (instead of 1.0) sort of trick in GAN training, so called label smoothing\n",
        "            # Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            d_loss, _ = discriminator.train_on_batch(X, y_dis)\n",
        "            discrim_losses.append(d_loss)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
        "            y_gen = np.ones(batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "        if ep % 100 == 0:\n",
        "            print('epoch: ', ep)\n",
        "            plot_generated_images(ep, generator)"
      ],
      "metadata": {
        "id": "1GTekMAqGCgB"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "generator = build_generator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "\n",
        "epochs = 100 # to get good quality images, you should train the model for more than 100 epochs\n",
        "batch_size = 128\n",
        "train_model(epochs, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "-d_WZyhtGDnx",
        "outputId": "e058d1f6-52d8-4f6d-d542-5969199a7c51"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 181ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-317-97c8944d6b77>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# to get good quality images, you should train the model for more than 100 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-303-42cfb7113437>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdiscrim_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2785\u001b[0m             )\n\u001b[1;32m   2786\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 )\n\u001b[1;32m   1383\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_233\" is incompatible with the layer: expected shape=(None, 28, 28, 3), found shape=(256, 32, 32, 3)\n"
          ]
        }
      ]
    }
  ]
}